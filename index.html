<html>
<head>
	<title>Fáilteoir</title>
	<link rel="stylesheet" type="text/css" href="css/clippy.css" media="all">
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
<script type="text/javascript" src="js/clippy.min.js"></script>
<script type="text/javascript">
  var magent;
  clippy.load('Links', function(agent) {
    agent.show();
    magent = agent;
  });
</script>
	<script type="text/javascript"src="js/espeak.js"></script>
	<script src="js/audioRecorder.js"></script>
        <script src="js/callbackManager.js"></script>
	<script>
var ctx = new (window.AudioContext || window.webkitAudioContext)();
var convolver = ctx.createConvolver();
convolver.connect(ctx.destination);
var espeak = new Espeak('js/espeak.worker.js', function cb() {
	espeak.setVoice.apply(espeak,['ga']);
});
var pusher;

var speak = function(text) {
  if (pusher) {
    pusher.disconnect();
    pusher = null;
  }
  var now = Date.now();
  var samples_queue = [];
  pusher = new PushAudioNode(ctx,
  function() {
    console.log('started!', ctx.currentTime, pusher.startTime);
  },
  function() {
    console.log('ended!', ctx.currentTime - pusher.startTime);
  });
  pusher.connect(ctx.destination);
  if(magent) {
    magent.speak(text);
    espeak.synth(text, function(samples, events) {
      if (!samples) {
        pusher.close();
        return;
      }
      pusher.push(new Float32Array(samples));
      if (now) {
        console.log("latency:", Date.now() - now);
        now = 0;
      }
    });
  }
}

/*
#JSGF V1.0;

grammar failteoir;

public <greet> = <dd> | <dimd> | <dimdip> | <dimpipib> | <dimpipibic> | <ac> ;

<dd> = dia duit ;
<dimd> = dia is muire duit ;
<dimdip> = dia is muire duit is pádraig ;
<dimpipib> = dia is muire duit is pádraig is bríd ;
<dimpipibic> = dia is muire duit is pádraig is bríd is colm cille ;
<ac> = a chara; 
*/
var gram = {numStates: 29, start: 0, end: 2, transitions: [
	{from: 0, to: 20, word: "dia"},
	{from: 0, to: 25, word: "dia"},
	{from: 0, to: 28, word: "dia"},
	{from: 0, to: 1, word: "a"},
	{from: 0, to: 3, word: "dia"},
	{from: 0, to: 13, word: "dia"},
	{from: 1, to: 2, word: "chara"},
	{from: 3, to: 4, word: "is"},
	{from: 4, to: 5, word: "muire"},
	{from: 5, to: 6, word: "duit"},
	{from: 6, to: 7, word: "is"},
	{from: 7, to: 8, word: "pádraig"},
	{from: 8, to: 9, word: "is"},
	{from: 9, to: 10, word: "bríd"},
	{from: 10, to: 11, word: "is"},
	{from: 11, to: 12, word: "colm"},
	{from: 12, to: 2, word: "cille"},
	{from: 13, to: 14, word: "is"},
	{from: 14, to: 15, word: "muire"},
	{from: 15, to: 16, word: "duit"},
	{from: 16, to: 17, word: "is"},
	{from: 17, to: 18, word: "pádraig"},
	{from: 18, to: 19, word: "is"},
	{from: 19, to: 2, word: "bríd"},
	{from: 20, to: 21, word: "is"},
	{from: 21, to: 22, word: "muire"},
	{from: 22, to: 23, word: "duit"},
	{from: 23, to: 24, word: "is"},
	{from: 24, to: 2, word: "pádraig"},
	{from: 25, to: 26, word: "is"},
	{from: 26, to: 27, word: "muire"},
	{from: 27, to: 2, word: "duit"},
	{from: 28, to: 2, word: "duit"}]};
var words = [["dia", "dʲ ia"], ["dia(2)", "dʲ iˑə"], ["is", "ə sˠ"], ["is(2)", "i sˠ"], ["is(3)", "sˠ"], ["muire", "mˠ i ɾʲ ə"], ["duit", "d̪ˠ i tʲ"], ["duit(2)", "ɣ i tʲ"], ["pádraig", "pˠ aː d̪ˠ ɾˠ ə ɟ"], ["pádraig(2)", "pˠ aː ɾˠ ə ɟ"], ["bríd", "bʲ ɾʲ iː dʲ"], ["colm", "k o lˠ ə mˠ"], ["cille", "c i lʲ ə"], ["chara", "x a ɾˠ ə"], ["a", "ə"], ["a(2)", "SIL"]];

      var recognizer, recorder, callbackManager, audio_context;
      var isRecorderReady = isRecognizerReady = false;
      function spawnWorker(workerurl, onReady) {
          recognizer = new Worker(workerurl);
          recognizer.onmessage = function(event) {
            onReady(recognizer);
          };
          recognizer.postMessage('');
      };

      function updateUI() {
        if (isRecorderReady && isRecognizerReady) startBtn.disabled = stopBtn.disabled = false;
      };

      function updateStatus(newStatus) {
        document.getElementById('current-status').innerHTML += "<br/>" + newStatus;
      };
      function displayRecording(display) {
        if (display) document.getElementById('recording-indicator').innerHTML = "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;";
        else document.getElementById('recording-indicator').innerHTML = "";
      };

      var startRecording = function() {
      if (recorder && recorder.start(id)) displayRecording(true);
      };

      var stopRecording = function() {
        recorder && recorder.stop();
        displayRecording(false);
      };

      var recognizerReady = function() {
           isRecognizerReady = true;
           updateUI();
           updateStatus("Recognizer ready");
      };
      window.onload = function() {
        if (window.location.protocol != "https:")
          window.location.href = "https:" + window.location.href.substring(window.location.protocol.length);
        updateStatus("Initializing Web Audio and speech recognizer, waiting for approval to access your microphone");
        callbackManager = new CallbackManager();
        spawnWorker("js/recognizer.js", function(worker) {
            worker.onmessage = function(e) {
                if (e.data.hasOwnProperty('id')) {
                  var clb = callbackManager.get(e.data['id']);
                  var data = {};
                  if( e.data.hasOwnProperty('data')) data = e.data.data;
                  if(clb) clb(data);
                }
                if (e.data.hasOwnProperty('hyp')) {
                  var newHyp = e.data.hyp;
                  if (e.data.hasOwnProperty('final') &&  e.data.final)
                  newHyp = "Final: " + newHyp;
                  updateHyp(newHyp);
                }
                if (e.data.hasOwnProperty('status') && (e.data.status == "error")) {
                  updateStatus("Error in " + e.data.command + " with code " + e.data.code);
                }
            };
            initRecognizer();
        });
        try {
          window.AudioContext = window.AudioContext || window.webkitAudioContext;
          navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
          window.URL = window.URL || window.webkitURL;
          audio_context = new AudioContext();
        } catch (e) {
          updateStatus("Error initializing Web Audio browser");
        }
        if (navigator.getUserMedia) navigator.getUserMedia({audio: true}, startUserMedia, function(e) {
                                        updateStatus("No live audio input in this browser");
                                    });
        else updateStatus("No web audio support in this browser");

      var startBtn = document.getElementById('startBtn');
      var stopBtn = document.getElementById('stopBtn');
      startBtn.disabled = true;
      stopBtn.disabled = true;
      startBtn.onclick = startRecording;
      stopBtn.onclick = stopRecording;
      };

      function startUserMedia(stream) {
        var input = audio_context.createMediaStreamSource(stream);
        window.firefox_audio_hack = input;
        var audioRecorderConfig = {errorCallback: function(x) {updateStatus("Error from recorder: " + x);}};
        recorder = new AudioRecorder(input, audioRecorderConfig);
        // If a recognizer is ready, we pass it to the recorder
        if (recognizer) recorder.consumers = [recognizer];
        isRecorderReady = true;
        updateUI();
        updateStatus("Audio recorder ready");
      };


</script>
</head>
<body>
	  <button id="startBtn">Start</button>
	  <button id="stopBtn">Stop</button>
	  <span id="recording-indicator" style="border-radius: 10px; -moz-border
		  -radius: 10px; -webkit-border-radius: 10px; width: 20px; height: 20px; backgroun
		  d: red;"></span>
	  <div class="reco-output" id="current-status">Loading page</div>

<div id="audio"></div>
</body>
</html>
